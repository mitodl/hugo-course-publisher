---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: Cw2Lz5I3wk0
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    title: Video-YouTube-Stream
    type: Video
    uid: fad7b959fcff81558b707a57fc439897
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/Cw2Lz5I3wk0/default.jpg'
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 97640058801034ac855b03d153554e11
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: Cw2Lz5I3wk0
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: fdb39fa5a3e96877fd6989056a0a0eff
  - id: Cw2Lz5I3wk0.srt
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/discussion-of-the-clt/Cw2Lz5I3wk0.srt
    title: 3play caption file
    type: null
    uid: 64588cae8ef486743c7eac7316c7a5e7
  - id: Cw2Lz5I3wk0.pdf
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/discussion-of-the-clt/Cw2Lz5I3wk0.pdf
    title: 3play pdf file
    type: null
    uid: 562fa64c75231824af4b71bad67d16a2
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 329aa62f375c210bcd4011cc2ed34656
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 8e090a41a051b207b75b33912ca117b5
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L19-03_300k.mp4
    parent_uid: 7916f5ceb8335042abc66a0baca11d3d
    title: Video-Internet Archive-MP4
    type: Video
    uid: 54b381856d5a4e99e5cdbc752d9deac6
inline_embed_id: 90062502discussionoftheclt35190283
order_index: 1777
parent_uid: b8cdf274e2b0f82662e4cd137e85d308
related_resources_text: ''
short_url: discussion-of-the-clt
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/discussion-of-the-clt
title: Discussion of the CLT
transcript: >-
  <p><span m='550'>The central limit theorem is absolutely remarkable.</span>
  </p><p><span m='3850'>It is a very deep result, and highly</span> <span
  m='7020'>nontrivial and non intuitive.</span> </p><p><span m='9860'>There's no
  apparent reason why this random variable here, a</span> <span
  m='15030'>standardized version of the sum of random variables,</span> <span
  m='18200'>should have an approximately normal distribution.</span>
  </p><p><span m='22070'>Furthermore, it is very useful, and one key reason
  is</span> <span m='26420'>that it is universal.</span> </p><p><span
  m='28290'>It doesn't matter what the distribution of the X's is.</span>
  </p><p><span m='32259'>No matter what the distribution is, still in the</span>
  <span m='35840'>limit, this standardized version of the sum is going to</span>
  <span m='40010'>behave like a normal random variable.</span> </p><p><span
  m='42790'>And if we wish to apply it to particular examples or models,</span>
  <span m='47620'>the only thing that we need to know about the distribution
  of</span> <span m='50690'>the X's are the corresponding means and variances,
  as we're</span> <span m='54550'>going to see in multiple examples.</span>
  </p><p><span m='57200'>When we apply it, it turns out to be very accurate, and
  it is</span> <span m='62990'>also a very nice computational shortcut.</span>
  </p><p><span m='66810'>Even if we knew, in detail, the distribution of the
  X's,</span> <span m='70300'>in order to calculate the distribution of Sn, we
  would</span> <span m='74000'>have to take the distribution of the X's and
  convolve it</span> <span m='77230'>with itself n times, something that can
  be</span> <span m='80370'>computationally tedious.</span> </p><p><span
  m='82210'>Whereas the computations that are involved, when we use the</span>
  <span m='86050'>central limit theorem, are very, very simple, as the</span>
  <span m='90210'>examples that will be coming up will show to us.</span>
  </p><p><span m='93729'>Finally, at the philosophical level, the central
  limit</span> <span m='97160'>theorem justifies why models involving normal
  random</span> <span m='101620'>variables are very natural.</span> </p><p><span
  m='104210'>Whenever you have a phenomenon or an object that's affected</span>
  <span m='108630'>by multiple noise sources, and if these noise sources
  are</span> <span m='114130'>independent, then the overall effect of those
  noise sources</span> <span m='118300'>is going to be well-modeled by a normal
  random variable, even</span> <span m='123330'>if the distribution of each one
  of these noise sources is</span> <span m='126800'>very different from being
  normal.</span> </p><p><span m='129630'>And this is a reason why, in many, many
  applications in</span> <span m='134290'>many different fields, normal random
  variables provide very</span> <span m='139340'>useful and accurate
  models.</span> </p><p><span m='143740'>Since the central limit theorem is so
  useful and</span> <span m='146329'>important, it is worth making sure that we
  understand</span> <span m='150210'>exactly what it says and to make a few
  comments on its</span> <span m='154360'>mathematical content.</span>
  </p><p><span m='156329'>What it says is the following.</span> </p><p><span
  m='158020'>We take the sum of independent identically distributed
  random</span> <span m='161630'>variables, we form this standardized version of
  the</span> <span m='165790'>sum, where we subtracted the mean and divide by
  the</span> <span m='168880'>standard deviation of the sum, and then what it
  tells us is</span> <span m='173420'>that the CDF of this random variable, Zn,
  converges to the</span> <span m='177730'>normal CDF.</span> </p><p><span
  m='179329'>So what we have is a statement about CDFs.</span> </p><p><span
  m='183550'>It does not yet tell us anything specific</span> <span
  m='187370'>about PDFs or PMFs.</span> </p><p><span m='190200'>So for example,
  if Sn and the X's are all continuous random</span> <span m='194670'>variable,
  so Zn is also continuous, you might wonder</span> <span m='198300'>whether the
  PDF of Zn converges to a normal PDF.</span> </p><p><span m='203320'>It turns
  out that there are results of this kind that</span> <span m='206810'>assert
  convergence of the PDF, or even PMF, of this random</span> <span
  m='211410'>variable to a normal PDF, in some sense.</span> </p><p><span
  m='215350'>But these results generally need a few more mathematical</span>
  <span m='219110'>assumptions for the results to be valid.</span> </p><p><span
  m='222670'>Nevertheless, when we show pictures of various examples,</span>
  <span m='227720'>we will do this by showing pictures of PDFs and PMFs</span>
  <span m='231930'>because these are easier to visualize.</span> </p><p><span
  m='235710'>Now since the result is so general and so important, it</span>
  <span m='240080'>might be worth understanding to what extent it can be</span>
  <span m='243400'>generalized to other contexts.</span> </p><p><span
  m='246190'>Our main two assumptions are that the random variables are</span>
  <span m='249270'>independent and identically distributed.</span> </p><p><span
  m='252180'>Can we remove those assumptions?</span> </p><p><span
  m='254470'>There are versions of the central limit theorem that</span> <span
  m='257630'>apply to the case where the Xi's are not identically</span> <span
  m='261010'>distributed.</span> </p><p><span m='262550'>One just needs to make
  certain assumptions on the means and</span> <span m='266410'>to the variances
  of the Xi's.</span> </p><p><span m='268910'>Some conditions will be
  needed.</span> </p><p><span m='271240'>Also, the assumption of independence
  does not need to</span> <span m='274680'>be literally true.</span>
  </p><p><span m='276570'>There are versions of the central limit theorem that
  are</span> <span m='279482'>valid when we have just weak dependence.</span>
  </p><p><span m='283480'>That is, nearby X's may be dependent, but if you
  compare</span> <span m='288920'>X5 with X of 1 million, then these two random
  variables are</span> <span m='294420'>essentially independent.</span>
  </p><p><span m='296170'>In those cases, we can still apply a suitable version
  of</span> <span m='299460'>the central limit theorem.</span> </p><p><span
  m='301510'>And finally, you may be curious how</span> <span m='304710'>this
  result is proved.</span> </p><p><span m='308230'>One way of proving it, which
  is the way it was originally</span> <span m='311970'>established a long time
  ago, for the special case of</span> <span m='316270'>Bernoulli random
  variables X, in which case S is binomial.</span> </p><p><span m='321080'>The
  way it was established was by carrying out algebraic</span> <span
  m='324780'>manipulations on the binomial formulas.</span> </p><p><span
  m='328250'>But this was a derivation that would not generalize.</span>
  </p><p><span m='331910'>For the general case, the proof is obtained
  using</span> <span m='335060'>so-called transform methods, which is a topic
  that we're</span> <span m='338990'>not covering, but it goes as
  follows.</span> </p><p><span m='342730'>We consider this function of the
  random variable Zn, where</span> <span m='347415'>s is some parameter, and we
  show that this expectation</span> <span m='351150'>converges to the
  corresponding expectation if you have the</span> <span m='354620'>standard
  normal Z in the place of Zn.</span> </p><p><span m='358440'>And this is true
  for all s, or at least for all s in some</span> <span m='363870'>rich enough
  set.</span> </p><p><span m='365480'>And then, one appeals to some deep
  mathematical results that</span> <span m='369310'>tell you that if this kind
  of expectation converges to that</span> <span m='374990'>expectation, then the
  CDF of Zn must also converge to the</span> <span m='379750'>CDF of Z. But this
  is a proof that involves various steps</span> <span m='384300'>and appeals to
  some deep results from other fields of</span> <span
  m='388550'>mathematics.</span> </p><p><span m='391030'>And finally, there is
  the practical side.</span> </p><p><span m='394100'>What exactly does it say
  and how do we use it?</span> </p><p><span m='397780'>Since the CDF of Zn can
  be approximated by the CDF of a</span> <span m='402420'>standard normal, this
  means that in practice, we can treat</span> <span m='406600'>the random
  variable Zn just as if it were a standard normal.</span> </p><p><span
  m='411880'>But now, we notice that Sn is obtained as a</span> <span
  m='416710'>linear function of Zn.</span> </p><p><span m='419040'>Namely, the
  definition of Zn gives us this formula.</span> </p><p><span m='425960'>So, Sn
  is a linear function of Zn.</span> </p><p><span m='429160'>If we pretend that
  Zn is normal, and since linear</span> <span m='433300'>functions of normal
  random variables are normal, this</span> <span m='436530'>means that we will
  also pretend that Sn is normal.</span> </p><p><span m='441150'>So in practice,
  the way to carry out calculations is</span> <span m='444610'>often to just
  pretend that Sn is normal with the appropriate</span> <span m='449500'>mean
  and variance.</span> </p><p><span m='451290'>These are the correct means and
  variance of Sn, and that's</span> <span m='455010'>the only information that
  we need in order to apply it.</span> </p><p><span m='458390'>If we know mu and
  sigma squared, and using the normal</span> <span m='462120'>approximation,
  then we have an approximate distribution for</span> <span m='465690'>Sn, and
  we can go ahead.</span> </p><p><span m='468350'>Now in practice, can we use
  the central limit theorem when</span> <span m='472040'>n is moderate?</span>
  </p><p><span m='473050'>For example, if n is 30, can you apply the</span>
  <span m='477300'>central limit theorem?</span> </p><p><span m='479000'>This is
  a relation that's true in the limit of very large n.</span> </p><p><span
  m='483220'>How large should n be?</span> </p><p><span m='485550'>It turns out
  that the central limit theorem gives us very</span> <span m='488610'>good
  approximations even when n has moderately small values.</span> </p><p><span
  m='494100'>Now, these approximations sometimes will be better and</span> <span
  m='496700'>sometimes worse.</span> </p><p><span m='498680'>It helps if the
  distribution of the X's that you're</span> <span m='501560'>starting with has
  some common one features with the normal</span> <span
  m='506170'>distribution.</span> </p><p><span m='507310'>If the X's are already
  normal, then S will be normal and</span> <span m='511700'>there's no
  approximation involved.</span> </p><p><span m='513360'>If the X's are close to
  normal, then for fairly small</span> <span m='517000'>values of n, S will be
  very well modeled by a normal</span> <span m='520960'>random variable.</span>
  </p><p><span m='522350'>Now, what does it mean that the distribution of the
  X's</span> <span m='525050'>looks a little bit like the normal one?</span>
  </p><p><span m='527960'>It helps if the distribution is symmetric around its
  mean,</span> <span m='531750'>and it also helps if it is unimodal, in the
  sense that it</span> <span m='535910'>has a single peak rather than multiple
  peaks.</span> </p><p></p>
uid: 7916f5ceb8335042abc66a0baca11d3d
type: course
layout: video
---
