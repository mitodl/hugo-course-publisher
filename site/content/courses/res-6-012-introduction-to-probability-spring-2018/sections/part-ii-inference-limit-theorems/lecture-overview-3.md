---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: kwbDWPrPfQI
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    title: Video-YouTube-Stream
    type: Video
    uid: 24d8d41e6b572f2ecd1261fad9ee106c
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/kwbDWPrPfQI/default.jpg'
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 70ca29a07cca74d15550b5564f6c442a
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: kwbDWPrPfQI
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 7bec80f74f49b25972c7ff893547d506
  - id: kwbDWPrPfQI.srt
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/lecture-overview-3/kwbDWPrPfQI.srt
    title: 3play caption file
    type: null
    uid: ab0a8815ddd50615764d2e5cf0be19aa
  - id: kwbDWPrPfQI.pdf
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/lecture-overview-3/kwbDWPrPfQI.pdf
    title: 3play pdf file
    type: null
    uid: f2b06a085b4f8936ce5736b0468b4959
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 398cf14f0555a559e479983004777646
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 5f761b9fc6f7d83dd157e580252b090d
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L17-01_300k.mp4
    parent_uid: 8f629fdceb9a90672de7734b26cbebd2
    title: Video-Internet Archive-MP4
    type: Video
    uid: 7a774671df19116f0bb87e686df10c3e
inline_embed_id: 2380110lectureoverview20248611
order_index: 1579
parent_uid: b8cdf274e2b0f82662e4cd137e85d308
related_resources_text: ''
short_url: lecture-overview-3
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/lecture-overview-3
title: Lecture Overview
transcript: >-
  <p><span m='1360'>If our objective is to keep the mean squared
  estimation</span> <span m='5400'>error small, then the best possible estimator
  is the</span> <span m='9490'>conditional expectation.</span> </p><p><span
  m='11590'>But sometimes the conditional</span> <span m='12920'>expectation is
  hard to calculate.</span> </p><p><span m='15820'>Maybe we're missing the
  details of the various</span> <span m='18410'>probability
  distributions.</span> </p><p><span m='20340'>Or maybe we have the
  distributions that we need but</span> <span m='24080'>the formulas are
  complicated.</span> </p><p><span m='26690'>After all, the conditional
  expectation can be a</span> <span m='29070'>complicated non-linear function of
  the observations.</span> </p><p><span m='33220'>For this reason, we may want
  to consider an estimator that</span> <span m='36970'>has a simpler structure,
  an estimator that is a linear</span> <span m='40910'>function of the
  data.</span> </p><p><span m='42700'>And then, within this class of estimators,
  find the one that</span> <span m='46700'>results in the smallest possible mean
  squared error.</span> </p><p><span m='51410'>In this lecture we will formulate
  this linear least</span> <span m='54870'>squares estimation problem and then
  solve it.</span> </p><p><span m='58560'>We will see that the solution is given
  by a simple formula</span> <span m='61940'>that involves only the means,
  variances, and covariances of</span> <span m='66910'>the random variables
  involved.</span> </p><p><span m='69390'>Because of the simplicity of the
  method, linear estimators</span> <span m='73060'>are used quite often,
  especially in systems where</span> <span m='76340'>estimates need to be
  computed quickly in real time as</span> <span m='80289'>observations are
  obtained.</span> </p><p><span m='83580'>We will look into some of the
  mathematical properties of the</span> <span m='86710'>linear least mean
  squares estimator and the associated</span> <span m='90650'>mean squared
  error, revisit an example from the previous</span> <span m='94200'>lecture,
  and finally close with some comments on the ways</span> <span m='97820'>that
  this estimator can be used.</span> </p><p></p>
uid: 8f629fdceb9a90672de7734b26cbebd2
type: course
layout: video
---
