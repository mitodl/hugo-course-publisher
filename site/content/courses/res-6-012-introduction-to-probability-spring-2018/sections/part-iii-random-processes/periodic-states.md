---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: TWedESDFcLQ
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    title: Video-YouTube-Stream
    type: Video
    uid: e6839183ebf07a89d7828fd6507b72b2
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/TWedESDFcLQ/default.jpg'
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 8038b14dbac2ee99d762fcdac4ac23d3
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L25-06_300k.mp4
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    title: Video-Internet Archive-MP4
    type: Video
    uid: baf955c73b541b554bffe332ad02c710
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: TWedESDFcLQ
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 3d82d59fe95c20ad676c9b47e38bb60c
  - id: TWedESDFcLQ.srt
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/periodic-states/TWedESDFcLQ.srt
    title: 3play caption file
    type: null
    uid: e7396cb3c629844576292c4a84ae3084
  - id: TWedESDFcLQ.pdf
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/periodic-states/TWedESDFcLQ.pdf
    title: 3play pdf file
    type: null
    uid: 0961d0efdcfe4646abff07af3cff821b
  - id: Caption-3Play YouTube id-SRT
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 16ccaf66e88f488a3491b2e30d6d4520
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: e4870bac20488bbe7be16db80bb0098b
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: f30e4b96c480707413018b3bf8cb15d1
inline_embed_id: 44028422periodicstates98517111
order_index: 2393
parent_uid: ea0e960c7d6bb5ec3c28c2657fe85c0d
related_resources_text: ''
short_url: periodic-states
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/periodic-states
title: Periodic States
transcript: >-
  <p><span m="876">All right.</span></p><p><span m="1376">So, as we've seen in
  the previous clip,</span> <span m="3720">another way that initial conditions
  may matter</span> <span m="7460">is if a chain has a periodic
  structure.</span></p><p><span m="12030">There are many ways of defining
  periodicity.</span></p><p><span m="14450">Some of them are more mathematical
  than others.</span></p><p><span m="17130">Let us consider one of the most
  intuitive ways of doing that.</span></p><p><span m="20880">So here is the
  definition.</span></p><p><span m="22610">The states in a recurrent class
  are</span> <span m="24460">periodic if they can be lumped together, or
  grouped,</span> <span m="28720">into several subgroups so that all transitions
  from one group</span> <span m="34756">lead to the next
  group.</span></p><p><span m="36500">So what does that really
  mean?</span></p><p><span m="38780">Let us try to parse out this by looking at
  the given example.</span></p><p><span m="44320">So here we would have a
  situation,</span> <span m="47130">a structure of a diagram, in which d is
  equal to 2.</span></p><p><span m="53790">Whenever you are at a given time in a
  state in that group,</span> <span m="59540">in the next transition you will go
  to that group.</span></p><p><span m="63570">And if you are in that group, at
  the next transition,</span> <span m="67410">you will go to that
  group.</span></p><p><span m="69789">So in some sense, there is
  periodicity,</span> <span m="72180">and there is somewhat of a deterministic
  behavior,</span> <span m="75680">according to this
  transition.</span></p><p><span m="77860">But there is also some randomness
  left.</span></p><p><span m="81000">We can be in any of these states within
  that sub-group.</span></p><p><span m="84490">But one thing that is for sure
  is</span> <span m="86640">that whenever, at a given time, you</span> <span
  m="88730">are into one of these states, here,</span> <span m="91530">in that
  group, if the Markov chain has</span> <span m="94750">this specific structure,
  in the next transition</span> <span m="97710">you will transition to one of
  the states, here.</span></p><p><span m="101180">And the next transition after,
  you will go back here.</span></p><p><span m="106190">So essentially, if your
  Markov chain</span> <span m="108720">started in one of these states here, at
  time n equals zero,</span> <span m="114420">then at time n equals 1, it would
  be here.</span></p><p><span m="117860">And then at time n equals 2, it would
  be here.</span></p><p><span m="121020">Times them into 3, and so on and so
  forth.</span></p><p><span m="125050">So every time you would have an even
  number,</span> <span m="129759">then you are guaranteed that the Markov chain
  will</span> <span m="132850">be in one of these states,
  here.</span></p><p><span m="134700">Clearly, with this kind of
  structure,</span> <span m="137150">it is impossible to have convergence of the
  steady state</span> <span m="140890">probabilities.</span></p><p><span
  m="142040">This is another example where you</span> <span m="144750">would
  have a structure of a diagram in which you</span> <span m="147530">have a
  period of 3, here.</span></p><p><span m="149400">So in that case here, d
  equals 3.</span></p><p><span m="152800">So here again, if you are in one of
  these states at a given</span> <span m="156310">time, then at the next time
  the following transition</span> <span m="159970">will guarantee to bring you
  in that group.</span></p><p><span m="162660">And during the next transition
  you will go to that group.</span></p><p><span m="166450">And then again, here,
  and again you</span> <span m="168890">have this kind of behavior in a very
  systematic way.</span></p><p><span m="172560">So if you started here at time n
  equals 0,</span> <span m="175640">you would be in that group, here, at times n
  equals 1.</span></p><p><span m="179590">And you would be here at n equals
  2.</span></p><p><span m="182200">And again, n equals 3 here, n equals 4, n
  equals 5, 6, 7, 8.</span></p><p><span m="190670">And you see the
  pattern.</span></p><p><span m="192910">If you look at any time in the
  future,</span> <span m="195980">if the time is of the form 3 times k for any k
  greater</span> <span m="201760">than or equal to 0, you're guaranteed</span>
  <span m="203800">that your chain will be in one of these
  states.</span></p><p><span m="207030">Otherwise, it will be here, or
  here.</span></p><p><span m="209950">So here again, you do not have
  convergence</span> <span m="212850">of the steady states, because if
  you</span> <span m="214500">are told that you started in one of the states
  here, then</span> <span m="218690">you know that whenever you have a time
  that</span> <span m="221950">is the form 3k plus 1 you will be
  here.</span></p><p><span m="226360">And so the probability of being here would
  be 0.</span></p><p><span m="228940">All right, so we have been able to explain
  a little bit what</span> <span m="233010">a periodic state is, using this
  definition.</span></p><p><span m="237550">Now given a Markov chain, how can
  we</span> <span m="240540">tell whether a Markov chain is periodic or
  not?</span></p><p><span m="244390">There are, in fact, systematic ways</span>
  <span m="246380">of doing it mathematically.</span></p><p><span m="248870">But
  usually within the types of examples we see in this class--</span> <span
  m="252940">most of them, these will be easy to see-- we</span> <span
  m="256100">just eyeball the chain and we tell whether it is periodic</span>
  <span m="259160">or not.</span></p><p><span m="259959">So let us see if it is
  that easy to do, and consider that chain,</span> <span
  m="264110">here.</span></p><p><span m="265200">OK, so let's
  see.</span></p><p><span m="266810">Is this chain periodic or
  not?</span></p><p><span m="271260">I will give you a couple of seconds to
  think about it.</span></p><p><span m="275140">Now I'm going to help a little
  bit.</span></p><p><span m="277360">I'll just decide that this one will be
  red,</span> <span m="280140">this one will be red, this one will be
  red,</span> <span m="283680">and this one will be red.</span></p><p><span
  m="285726">Now I'm asking the same question.</span></p><p><span
  m="287100">What do you think?</span></p><p><span m="289180">Well, from the
  structure it is clear</span> <span m="292040">that this Markov chain is
  periodic</span> <span m="295159">and has a period of d equals
  2.</span></p><p><span m="297850">In some sense, the red state, here,</span>
  <span m="300060">could be one of these groups.</span></p><p><span
  m="301870">These are the red ones.</span></p><p><span m="303560">And the
  white, here, would be those, here.</span></p><p><span m="307780">And it is
  clear, if you look at this diagram,</span> <span m="310720">that whenever you
  are in a red state, at the next transition</span> <span m="314370">you are
  guaranteed to be in a white state.</span></p><p><span m="317270">From this
  one, you will be in white.</span></p><p><span m="318770">From this one, you
  will be in the white.</span></p><p><span m="320620">From this one , as
  well.</span></p><p><span m="322010">And from this one, as
  well.</span></p><p><span m="323800">And whenever you are in a white state,
  this one, this one,</span> <span m="327820">this one, or this one, at the next
  period</span> <span m="331350">you are guaranteed to be in a red
  state.</span></p><p><span m="333800">So this tells you that sometimes
  it</span> <span m="336080">is not that easy to eyeball and decide</span> <span
  m="339159">if the Markov chain is periodic or not.</span></p><p><span
  m="341860">If you have, for example, lots of, lots of states,</span> <span
  m="345110">you might have some trouble doing this exercise.</span></p><p><span
  m="347870">On the other hand, something very useful to
  know.</span></p><p><span m="350240">Sometimes, it's extremely easy to tell
  that the chain is not</span> <span m="354270">periodic, even if you have a lot
  of states.</span></p><p><span m="358330">What is that case?</span></p><p><span
  m="359390">Well, look at this case, here, and suppose for a moment</span>
  <span m="363810">that you have a self transition here.</span></p><p><span
  m="372360">Well in that case, you would have a transition</span> <span
  m="375640">from a white state to a white state.</span></p><p><span
  m="378920">And you're not guaranteed anymore that from a white state</span>
  <span m="382650">you would go to a red state.</span></p><p><span m="385260">In
  that sense, as soon as you have a self transition,</span> <span m="388940">the
  Markov chain is aperiodic.</span></p><p><span m="391210">It cannot be
  periodic.</span></p><p><span m="395220">So whenever you have a self
  transition,</span> <span m="397620">this implies that the chain is not
  periodic.</span></p><p><span m="399850">And usually that's the simplest and
  easiest way</span> <span m="403590">that we can tell, most of the time,</span>
  <span m="405340">that the chain is not periodic.</span></p><p>&nbsp;</p>
uid: e4870bac20488bbe7be16db80bb0098b
type: courses
layout: video
---
