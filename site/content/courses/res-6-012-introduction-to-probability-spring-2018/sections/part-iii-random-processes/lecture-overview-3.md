---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: LBiYeL4qD2M
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    title: Video-YouTube-Stream
    type: Video
    uid: 8e9d2d6d1cae796fdd35e91b8e6867c3
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/LBiYeL4qD2M/default.jpg'
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 1606968d5a044cb741ec6c14c306bb55
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: LBiYeL4qD2M
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 5af7180a1d4d680b6d4c27ed72a70b7f
  - id: LBiYeL4qD2M.srt
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/lecture-overview-3/LBiYeL4qD2M.srt
    title: 3play caption file
    type: null
    uid: cc83777de8a89924aec0f7de7d8ec522
  - id: LBiYeL4qD2M.pdf
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/lecture-overview-3/LBiYeL4qD2M.pdf
    title: 3play pdf file
    type: null
    uid: 1010d6d144814035cfab412f5bda29cf
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 49388c0d9bd1b11d843b2f2c599d69da
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 762d265303d0a433b594380ea900939b
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L24-01_300k.mp4
    parent_uid: 921f29a6bdeedd555cf92bf96a8fb6ba
    title: Video-Internet Archive-MP4
    type: Video
    uid: b2db8212a65064552524ec5ececb9952
inline_embed_id: 64425814lectureoverview46508251
order_index: 2204
parent_uid: ea0e960c7d6bb5ec3c28c2657fe85c0d
related_resources_text: ''
short_url: lecture-overview-3
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/lecture-overview-3
title: Lecture Overview
transcript: >-
  <p><span m='500'>In this lecture, we introduce Markov chains, a general
  class</span> <span m='4230'>of random processes with many applications</span>
  <span m='6860'>dealing with the evolution of dynamical systems.</span>
  </p><p><span m='10380'>As opposed to the Bernoulli and Poisson</span> <span
  m='12230'>processes, which are memoryless in a sense</span> <span
  m='15420'>that the future does not depend on the past,</span> <span
  m='17860'>Markov chains are more elaborate, as they</span> <span
  m='20350'>allow some dependencies between different times.</span> </p><p><span
  m='23980'>However, these dependencies are of simple and restricted</span>
  <span m='27640'>nature, captured by the so-called Markov property.</span>
  </p><p><span m='31330'>Conditional on the current state of the Markov chain,
  its future</span> <span m='34710'>and past evolutions are independent.</span>
  </p><p><span m='37420'>As mentioned in the unit overview,</span> <span
  m='39830'>we will only consider discrete time</span> <span m='41760'>Markov
  chains that evolve within finite state spaces.</span> </p><p><span
  m='46170'>This allows us to concentrate on the main concepts</span> <span
  m='49270'>without having to deal with some required technical details</span>
  <span m='52760'>needed to study general Markov processes under continuous
  time</span> <span m='57470'>and general, possibly uncountable, state
  spaces.</span> </p><p><span m='62850'>We will first introduced the basic
  concepts,</span> <span m='65550'>using the simple example of a checkout
  counter</span> <span m='68270'>at a supermarket, an example of a simple
  queuing system.</span> </p><p><span m='72610'>We will then abstract from the
  example</span> <span m='74570'>and give some general definitions,
  including</span> <span m='77200'>the central notions of states, transition
  probabilities,</span> <span m='81570'>Markov property, and transition
  probability graphs.</span> </p><p><span m='86090'>Afterwards, we will look at
  various questions,</span> <span m='88920'>such as predicting what will happen
  in n-steps</span> <span m='92560'>in the future, given the current state of
  our system.</span> </p><p><span m='96310'>We will define n-step transition
  probabilities exactly</span> <span m='100180'>and show how to calculate them
  efficiency.</span> </p><p><span m='103180'>We will also discuss what could
  happen</span> <span m='105530'>when we let the Markov chain run for a very
  long time.</span> </p><p><span m='109570'>We will end this lecture by
  introducing</span> <span m='111710'>the notions of recurrent and transient
  states</span> <span m='115039'>and their importance in studying Markov chains
  in the long run.</span> </p>
uid: 921f29a6bdeedd555cf92bf96a8fb6ba
type: course
layout: video
---
