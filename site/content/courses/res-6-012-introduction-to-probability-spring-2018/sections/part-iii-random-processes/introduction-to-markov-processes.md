---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: K-ck5dOsPgQ
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    title: Video-YouTube-Stream
    type: Video
    uid: ae8b54b735854a9e3cc549bccce5eb03
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/K-ck5dOsPgQ/default.jpg'
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 077f41fded5de5cf0ab40b123e378d5e
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: K-ck5dOsPgQ
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 66e29d15dcb584e538a15be223d51b13
  - id: K-ck5dOsPgQ.srt
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/introduction-to-markov-processes/K-ck5dOsPgQ.srt
    title: 3play caption file
    type: null
    uid: 50dd49766618daf05fdb03ff71cef8bc
  - id: K-ck5dOsPgQ.pdf
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/introduction-to-markov-processes/K-ck5dOsPgQ.pdf
    title: 3play pdf file
    type: null
    uid: 842451b64b5a267f71aba8a994a9c50d
  - id: Caption-3Play YouTube id-SRT
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: dbb6c5ac7672a3219b45cf2139931fdb
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 218485e88e3978c2c1136c5b84cb5873
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L24-02_300k.mp4
    parent_uid: c3972ceb34d860c7f29f247fb6d15f5b
    title: Video-Internet Archive-MP4
    type: Video
    uid: 5003fc95318e151d0c6baedace628ac8
inline_embed_id: 65604005introductiontomarkovprocesses70236561
order_index: 2213
parent_uid: ea0e960c7d6bb5ec3c28c2657fe85c0d
related_resources_text: ''
short_url: introduction-to-markov-processes
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/introduction-to-markov-processes
title: Introduction to Markov Processes
transcript: >-
  <p><span m='1090'>In this lecture, we introduce Markov chains, a general
  class</span> <span m='4510'>of random processes with many applications</span>
  <span m='6910'>dealing with the evolution of dynamical systems.</span>
  </p><p><span m='9890'>They have been used in physics, chemistry,
  information</span> <span m='12730'>sciences, queuing theory, internet
  applications,</span> <span m='15900'>statistics, finance, games, music,
  genetics, baseball,</span> <span m='20910'>history, you name it.</span>
  </p><p><span m='22730'>So what make these processes so powerful and
  practical?</span> </p><p><span m='26920'>Well, as opposed to the Bernoulli and
  Poisson</span> <span m='29660'>processes, which are memoryless in the
  sense</span> <span m='32530'>that the future does not depend on the
  past,</span> <span m='36040'>Markov chains are more elaborate as they</span>
  <span m='39600'>allow the representation of situations where</span> <span
  m='42380'>the future depends on the past and, to some extent,</span> <span
  m='48340'>could be predicted from the past.</span> </p><p><span m='53370'>More
  precisely, we are going to consider models</span> <span m='56470'>where the
  influence of the past on the future</span> <span m='60610'>is summarized by
  the notion of a state, which evolves</span> <span m='66110'>over time
  according to some probability distribution.</span> </p><p><span
  m='69680'>That's the link between the past and the future.</span> </p><p><span
  m='74020'>We will restrict ourselves to discrete time Markov</span> <span
  m='77410'>chains in which the state changes</span> <span m='80270'>at certain
  discrete time steps.</span> </p><p><span m='83050'>The state at time t plus 1,
  which is here,</span> <span m='86660'>is a function of the state at time
  t,</span> <span m='89850'>and there is some noise, or randomness.</span>
  </p><p><span m='92900'>As another view, this is what we will cover in this
  lecture.</span> </p><p><span m='97060'>We will first introduce the basic
  concepts</span> <span m='99970'>using the example of a checkout counter at the
  supermarket.</span> </p><p><span m='104310'>We will then abstract from the
  example</span> <span m='107450'>and give some general definitions.</span>
  </p><p><span m='110530'>Afterwards, we will look at various questions,</span>
  <span m='113430'>such as predicting what could happen in the future
  given</span> <span m='116900'>the current state of our systems.</span>
  </p><p><span m='119650'>We will end this lecture by giving some key</span>
  <span m='122800'>structural properties of Markov processes.</span>
  </p><p><span m='126470'>So let us start.</span> </p>
uid: c3972ceb34d860c7f29f247fb6d15f5b
type: courses
layout: video
---
