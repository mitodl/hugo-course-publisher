---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: uviHu6m_YnM
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    title: Video-YouTube-Stream
    type: Video
    uid: 168c3df209eafbb4fb281d2d470afe24
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/uviHu6m_YnM/default.jpg'
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 3ec3a42ebe597d607eabd298c551467f
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: uviHu6m_YnM
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 14ee87921f2d62226766e8ad949f9005
  - id: uviHu6m_YnM.srt
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/lecture-overview-5/uviHu6m_YnM.srt
    title: 3play caption file
    type: null
    uid: 7415397014af3bc881f87db564f79359
  - id: uviHu6m_YnM.pdf
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/lecture-overview-5/uviHu6m_YnM.pdf
    title: 3play pdf file
    type: null
    uid: f804f56495dfca73c62d4e6a0a061546
  - id: Caption-3Play YouTube id-SRT
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: c2a6393c7fe272a9d550816f472fe8f4
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 250cb328f75efb940bc9e902fc5f633f
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L25-02_300k.mp4
    parent_uid: adae1034dfeddc6b45046d46a7de6320
    title: Video-Internet Archive-MP4
    type: Video
    uid: c849b3fe28a55749b68ebef5da24e92a
inline_embed_id: 37307713lectureoverview71682335
order_index: 2357
parent_uid: ea0e960c7d6bb5ec3c28c2657fe85c0d
related_resources_text: ''
short_url: lecture-overview-5
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/lecture-overview-5
title: Lecture Overview
transcript: >-
  <p><span m="500">In this lecture, we will concentrate</span> <span m="2960">on
  the study of Markov chains in the long run,</span> <span m="6000">and study
  under what conditions a Markov chain</span> <span m="8670">exhibits
  steady-state behavior, and under what conditions</span> <span m="12780">such
  steady-state behavior is independent</span> <span m="15620">of the initial
  starting state.</span></p><p><span m="18120">More precisely, we will look at
  long-term state occupancy</span> <span m="21840">behavior-- that is, in the
  n-step transition probabilities</span> <span m="26470">when n is
  large.</span></p><p><span m="28700">So assume that we have a Markov chain
  which is initially</span> <span m="32860">in a given state i, and consider the
  probability</span> <span m="36770">that the chain is in a specific state j
  after n transitions.</span></p><p><span m="41900">Question-- does that
  probability converge to some constant</span> <span m="45450">when n goes to
  infinity?</span></p><p><span m="48010">And if this is the case-- second
  question-- can this constant be</span> <span m="52940">independent of the
  initial state i?</span></p><p><span m="56750">We will see that for nice Markov
  chains,</span> <span m="59490">the answers to both questions will be
  yes.</span></p><p><span m="62800">How to characterize nice Markov
  chains?</span></p><p><span m="65690">We will use several new concepts, one
  dealing</span> <span m="68780">with a Markov chain being aperiodic or
  not,</span> <span m="71880">and the other with the notion of recurrent
  classes.</span></p><p><span m="76230">Without going into details now,
  let</span> <span m="78930">us simply mention that we will show</span> <span
  m="81380">that the existence of convergence</span> <span m="83370">will be
  tied to having an aperiodic Markov chain.</span></p><p><span m="87100">And in
  case we have convergence, the independence</span> <span m="90220">from the
  initial state will be tied</span> <span m="91990">to having a single recurrent
  class.</span></p><p><span m="95160">We will end this lecture by looking in
  detail</span> <span m="98580">at the special and important class of Markov
  chains usually</span> <span m="102080">known as birth-death
  processes.</span></p><p>&nbsp;</p>
uid: adae1034dfeddc6b45046d46a7de6320
type: courses
layout: video
---
