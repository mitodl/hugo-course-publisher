---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: mHj4A1gh_ws
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    title: Video-YouTube-Stream
    type: Video
    uid: bc581db225489087b2a5e66e95c7c97c
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/mHj4A1gh_ws/default.jpg'
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: b5bac95d7be0f81235347993bc4951db
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: mHj4A1gh_ws
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: d9157a776540cfb79169df3586c9188e
  - id: mHj4A1gh_ws.srt
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/conditioning-a-continuous-random-variable-on-an-event/mHj4A1gh_ws.srt
    title: 3play caption file
    type: null
    uid: 6d8fa0eabac3649ac883d4412a199c50
  - id: mHj4A1gh_ws.pdf
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/conditioning-a-continuous-random-variable-on-an-event/mHj4A1gh_ws.pdf
    title: 3play pdf file
    type: null
    uid: 403d214338011a67fda7be72c19b266b
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 96f6fcaf52bbb5ccb8ef3d18885f8bf2
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 009f6e61e7c70e40a9c6ab1bd5041165
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L09-02_300k.mp4
    parent_uid: 840a0d32e569cb2a71cd912f06afc6d3
    title: Video-Internet Archive-MP4
    type: Video
    uid: 9b5b445e1daf6641fa9698117cc83af2
inline_embed_id: 60632354conditioningacontinuousrandomvariableonanevent74604397
order_index: 834
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: conditioning-a-continuous-random-variable-on-an-event
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/conditioning-a-continuous-random-variable-on-an-event
title: Conditioning A Continuous Random Variable on an Event
transcript: >-
  <p><span m='980'>In this segment, we pursue two themes.</span> </p><p><span
  m='4010'>Every concept has a conditional counterpart.</span> </p><p><span
  m='7220'>We know about PDFs, but if we live in a conditional</span> <span
  m='10100'>universe, then we deal with conditional probabilities.</span>
  </p><p><span m='13420'>And we need to use conditional PDFs.</span>
  </p><p><span m='16640'>The second theme is that discrete formulas have</span>
  <span m='19500'>continuous counterparts in which summations get
  replaced</span> <span m='23000'>by integrals, and PMFs by PDFs.</span>
  </p><p><span m='27400'>So let us recall the definition of a conditional</span>
  <span m='30440'>PMF, which is just the same as an ordinary PMF but applied
  to</span> <span m='37010'>a conditional universe.</span> </p><p><span
  m='38950'>In the same spirit, we can start with a PDF, which we can</span>
  <span m='43140'>interpret, for example, in terms of probabilities of</span>
  <span m='46120'>small intervals.</span> </p><p><span m='47970'>If we move to a
  conditional model in which event A is</span> <span m='51290'>known to have
  occurred, probabilities of small</span> <span m='54010'>intervals will then be
  determined by a conditional</span> <span m='57920'>PDF, which we denote in
  this manner.</span> </p><p><span m='61600'>Of course, we need to assume
  throughout that the</span> <span m='64010'>probability of the conditioning
  event is positive</span> <span m='67760'>so that conditional probabilities
  are</span> <span m='70460'>well-defined.</span> </p><p><span m='72400'>Let us
  now push the analogy further.</span> </p><p><span m='74710'>We can use a PMF
  to calculate probabilities.</span> </p><p><span m='78060'>The probability that
  X takes [a] value in a certain set is</span> <span m='82320'>the sum of the
  probabilities of all the possible</span> <span m='86020'>values in that
  set.</span> </p><p><span m='88090'>And a similar formula is true if we're
  dealing with a</span> <span m='90890'>conditional model.</span> </p><p><span
  m='92550'>Now, in the continuous case, we use a PDF to calculate the</span>
  <span m='98120'>probability that X takes values in a certain set.</span>
  </p><p><span m='102450'>And by analogy, we use a conditional PDF to
  calculate</span> <span m='108300'>conditional probabilities.</span>
  </p><p><span m='110509'>We can take this relation here to be the definition of
  a</span> <span m='114870'>conditional PDF.</span> </p><p><span m='116840'>So a
  conditional PDF is a function that allows us to</span> <span
  m='121800'>calculate probabilities by integrating this function over</span>
  <span m='125610'>the event or set of interest.</span> </p><p><span
  m='129228'>Of course, probabilities need to sum to 1.</span> </p><p><span
  m='132440'>This is true in the discrete setting.</span> </p><p><span
  m='134810'>And by analogy, it should also be true in</span> <span
  m='137470'>the continuous setting.</span> </p><p><span m='139610'>This is just
  an ordinary PDF, except that it applies to a</span> <span m='143380'>model in
  which event A is known to have occurred.</span> </p><p><span m='147050'>But it
  still is a legitimate PDF.</span> </p><p><span m='150430'>It has to be
  non-negative, of course.</span> </p><p><span m='153720'>But also, it needs to
  integrate to 1.</span> </p><p><span m='159360'>When we condition on an event
  and without any further</span> <span m='162600'>assumption, there's not much
  we can say about the form of</span> <span m='165900'>the conditional
  PDF.</span> </p><p><span m='167470'>However, if we condition on an event of a
  special kind, that</span> <span m='171540'>X takes values in a certain set,
  then we can actually</span> <span m='176100'>write down a formula.</span>
  </p><p><span m='178120'>So let us start with a random variable X that has a
  given</span> <span m='181860'>PDF, as in this diagram.</span> </p><p><span
  m='191200'>And suppose that A is a subset of the real line, for
  example,</span> <span m='197400'>this subset here.</span> </p><p><span
  m='201860'>What is the form of the conditional PDF?</span> </p><p><span
  m='204820'>We start with the interpretation of PDFs and</span> <span
  m='207620'>conditional PDFs in terms of</span> <span m='209200'>probabilities
  of small intervals.</span> </p><p><span m='211180'>The probability that X lies
  in a small interval is equal to</span> <span m='214650'>the value of the PDF
  somewhere in that interval times the</span> <span m='218140'>length of the
  interval.</span> </p><p><span m='219600'>And if we're dealing with conditional
  probabilities,</span> <span m='222070'>then we use the corresponding
  conditional PDF.</span> </p><p><span m='225320'>To find the form of the
  conditional PDF, we will work</span> <span m='229200'>in terms of the
  left-hand side in this equation and try to</span> <span m='233720'>rewrite
  it.</span> </p><p><span m='235450'>Let us distinguish two cases.</span>
  </p><p><span m='237550'>Suppose that little X lies somewhere out here, and
  we</span> <span m='243780'>want to evaluate the conditional PDF at that
  point.</span> </p><p><span m='247160'>So trying to evaluate this expression,
  we consider a</span> <span m='251580'>small interval from little x to little x
  plus delta.</span> </p><p><span m='259850'>And now, let us write the
  definition of a conditional</span> <span m='265020'>probability.</span>
  </p><p><span m='266370'>A conditional probability, by definition, is equal to
  the</span> <span m='270160'>probability that both events occur divided by
  the</span> <span m='275130'>probability of the conditioning event.</span>
  </p><p><span m='281040'>Now, because the set A and this little interval
  are</span> <span m='284640'>disjoint, these two events cannot occur
  simultaneously.</span> </p><p><span m='289420'>So the numerator here is going
  to be 0.</span> </p><p><span m='292540'>And this will imply that the
  conditional PDF is</span> <span m='295470'>also going to be 0.</span>
  </p><p><span m='298620'>This, of course, makes sense.</span> </p><p><span
  m='300470'>Conditioned on the event that X took values in this set,</span>
  <span m='306130'>values of X out here cannot occur.</span> </p><p><span
  m='309750'>And therefore, the conditional density out here</span> <span
  m='313000'>should also be 0.</span> </p><p><span m='314830'>So the conditional
  PDF is 0 outside the set A. And this</span> <span m='321980'>takes care of one
  case.</span> </p><p><span m='325680'>Now, the second case to consider is when
  little x lies</span> <span m='331150'>somewhere inside here inside the set A.
  And in that case,</span> <span m='336250'>our little interval from little x to
  little x plus</span> <span m='341760'>delta might have this form.</span>
  </p><p><span m='345070'>In this case, the intersection of these two events,
  that X</span> <span m='348460'>lies in the big set and X lies in the small
  set, the</span> <span m='351870'>intersection of these two events is the event
  that X</span> <span m='355040'>lies in the small set.</span> </p><p><span
  m='357190'>So the numerator simplifies just to the probability that</span>
  <span m='361530'>the random variable X takes values in the interval
  from</span> <span m='365380'>little x to little x plus delta.</span>
  </p><p><span m='368780'>And then we rewrite the denominator.</span>
  </p><p><span m='372480'>Now, the numerator is just an ordinary probability
  that the</span> <span m='376110'>random variable takes values inside a small
  interval.</span> </p><p><span m='379870'>And by our interpretation of PDFs,
  this is approximately</span> <span m='384830'>equal to the PDF evaluated
  somewhere in that small</span> <span m='388040'>interval times delta.</span>
  </p><p><span m='391310'>At this point, we notice that we have deltas on both
  sides</span> <span m='395570'>of this equation.</span> </p><p><span
  m='396860'>By cancelling this delta with that delta, we finally end up</span>
  <span m='401240'>with a relation that the conditional PDF should be</span>
  <span m='405180'>equal to this expression that we have here.</span>
  </p><p><span m='408250'>So to summarize, we have shown a formula for</span>
  <span m='412810'>the conditional PDF.</span> </p><p><span m='413930'>The
  conditional PDF is 0 for those values of X that cannot</span> <span
  m='418680'>occur given the information that we are given, namely that</span>
  <span m='423340'>X takes values at that interval.</span> </p><p><span
  m='425410'>But inside this interval, the conditional PDF has a form</span>
  <span m='429880'>which is proportional to the unconditional PDF.</span>
  </p><p><span m='433700'>But it is scaled by a certain constant.</span>
  </p><p><span m='436630'>So in terms of a picture, we might have</span> <span
  m='440260'>something like this.</span> </p><p><span m='444040'>And so this
  green diagram is the form of</span> <span m='447830'>the conditional
  PDF.</span> </p><p><span m='452550'>The particular factor that we have here in
  the denominator</span> <span m='456250'>is exactly that factor that is
  required, the scaling factor</span> <span m='460510'>that is required so that
  the total area under the green</span> <span m='464440'>curve, under the
  conditional PDF is equal to 1.</span> </p><p><span m='467930'>So we see once
  more the familiar theme, that</span> <span m='470610'>conditional
  probabilities maintain the same relative</span> <span m='473890'>sizes as the
  unconditional probabilities.</span> </p><p><span m='476620'>And the same is
  true for conditional PMFs or PDFs,</span> <span m='480620'>keeping the same
  shape as the unconditional ones, except</span> <span m='484290'>that they are
  re-scaled so that the total probability</span> <span m='487660'>under a
  conditional PDF is equal to 1.</span> </p><p><span m='492340'>We can now
  continue the same story and revisit everything</span> <span m='495870'>else
  that we had done for discrete random variables.</span> </p><p><span
  m='499360'>For example, we have the expectation of a discrete</span> <span
  m='502510'>random variable and the corresponding conditional</span> <span
  m='505630'>expectation, which is just the same kind of object, except</span>
  <span m='508990'>that we now rely on conditional probabilities.</span>
  </p><p><span m='512130'>Similarly, we can take the definition of the
  expectation</span> <span m='515919'>for the continuous case and define a
  conditional</span> <span m='518890'>expectation in the same manner, except
  that we now</span> <span m='522140'>rely on the conditional PDF.</span>
  </p><p><span m='524490'>So this formula here is the definition of the
  conditional</span> <span m='529140'>expectation of a continuous random
  variable given a</span> <span m='532240'>particular event.</span> </p><p><span
  m='534710'>We have a similar situation with the expected value rule,</span>
  <span m='537970'>which we have already seen for discrete random variables
  in</span> <span m='541250'>both of the unconditional and in the conditional
  setting.</span> </p><p><span m='545930'>We have a similar formula for the
  continuous case.</span> </p><p><span m='548810'>And at this point, you can
  guess the form that the</span> <span m='551600'>formula will take in
  the</span> <span m='552960'>continuous conditional setting.</span>
  </p><p><span m='557340'>This is the expected value rule in the
  conditional</span> <span m='559880'>setting, and it is proved exactly the same
  way as for</span> <span m='564410'>the unconditional continuous setting,
  except that here in</span> <span m='568260'>the proof, we need to work with
  conditional probabilities</span> <span m='571560'>and conditional PDFs,
  instead of the unconditional ones.</span> </p><p><span m='576540'>So to
  summarize, there is nothing really different when</span> <span m='581370'>we
  condition on an event in the continuous case compared</span> <span
  m='584590'>to the discrete case.</span> </p><p><span m='586400'>We just
  replace summations with integrations.</span> </p><p><span m='590360'>And we
  replace PMFs by PDFs.</span> </p><p></p>
uid: 840a0d32e569cb2a71cd912f06afc6d3
type: courses
layout: video
---
