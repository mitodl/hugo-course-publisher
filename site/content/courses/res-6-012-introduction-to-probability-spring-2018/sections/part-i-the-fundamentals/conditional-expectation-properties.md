---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: 2BttG14vI7c
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    title: Video-YouTube-Stream
    type: Video
    uid: 79013dce524f7aaded8df18ca6ea25d4
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/2BttG14vI7c/default.jpg'
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 4ef02999cbce30519b3fe5ffcbe2b4d6
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: 2BttG14vI7c
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: a7bb1112a4044ae8f4aa92cffabaea42
  - id: 2BttG14vI7c.srt
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/conditional-expectation-properties/2BttG14vI7c.srt
    title: 3play caption file
    type: null
    uid: 415688f88793f927af80ec0f3437082c
  - id: 2BttG14vI7c.pdf
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/conditional-expectation-properties/2BttG14vI7c.pdf
    title: 3play pdf file
    type: null
    uid: 36ef971a57ee21b1df6f9c0da40b87d7
  - id: Caption-3Play YouTube id-SRT
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 9cea4b13fdb73932edbac28f673e4933
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 44a8286aa714ad9fa84f41be85d99049
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_S13-01_300k.mp4
    parent_uid: d12d2305e1c3f99b07308a6773ba4f80
    title: Video-Internet Archive-MP4
    type: Video
    uid: 7432934b0d8f1954b4c3e6732ac3424b
inline_embed_id: 70181878conditionalexpectationproperties17702003
order_index: 1311
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: conditional-expectation-properties
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/conditional-expectation-properties
title: Conditional Expectation Properties
transcript: >-
  <p><span m='1370'>In this segment, we point out and discuss</span> <span
  m='4160'>some important but also intuitive properties</span> <span m='7330'>of
  conditional expectations.</span> </p><p><span m='9580'>The first property is
  the one that is written up here.</span> </p><p><span m='13900'>What is the
  intuitive meaning?</span> </p><p><span m='16300'>If you condition on Y, then
  the value of Y is known,</span> <span m='21140'>and so g of Y is also
  known.</span> </p><p><span m='23710'>There's no randomness in it.</span>
  </p><p><span m='25340'>It can be treated as a constant, and therefore
  it</span> <span m='28400'>can be pulled outside the expectation.</span>
  </p><p><span m='31860'>So that's the intuition.</span> </p><p><span
  m='33560'>How does one establish such a result formally?</span> </p><p><span
  m='37160'>Let us take the discrete case.</span> </p><p><span m='38850'>So let
  us assume that X and Y are both discrete.</span> </p><p><span m='45850'>What
  does it take to establish a fact of this kind?</span> </p><p><span
  m='49270'>We want to show that two random variables are equal,</span> <span
  m='52410'>and that amounts to the following.</span> </p><p><span m='54830'>We
  consider an outcome of the experiment,</span> <span m='58790'>and we want to
  show that whatever</span> <span m='60880'>the outcome of the experiment
  is,</span> <span m='63100'>these two random variables will be the same.</span>
  </p><p><span m='66480'>So let us consider an outcome for which the random
  variable,</span> <span m='76370'>Y, takes a specific value, little y.</span>
  </p><p><span m='82480'>And of course, this has to be a specific little y
  that</span> <span m='85950'>is possible.</span> </p><p><span
  m='87630'>Otherwise, conditioning on that event would not be
  meaningful.</span> </p><p><span m='93759'>So if an outcome has this value for
  the random variable,</span> <span m='99500'>Y, then what does the random
  variable do?</span> </p><p><span m='103740'>This is, by definition, the random
  variable</span> <span m='108150'>that takes the value-- expected value</span>
  <span m='111080'>of g Y X, conditional expectation,</span> <span
  m='117770'>given that capital Y took on this value.</span> </p><p><span
  m='121610'>This was our definition of the concept</span> <span m='124220'>of
  the abstract conditional expectation</span> <span m='126610'>as a random
  variable.</span> </p><p><span m='128030'>This is the random variable that
  takes</span> <span m='130990'>this specific numerical value whenever</span>
  <span m='133430'>the random variable, capital Y, takes the value, little
  y.</span> </p><p><span m='137320'>And similarly, if the random variable,
  capital Y,</span> <span m='142860'>takes the value, little y, this random
  variable here</span> <span m='147120'>is the expected value of X, given that Y
  is little y.</span> </p><p><span m='153800'>And when capital Y takes the
  value,</span> <span m='156190'>little y, this function, g of Y, takes</span>
  <span m='159110'>on this particular numerical value.</span> </p><p><span
  m='162990'>So we want to show that these two expressions</span> <span
  m='165720'>we will be equal no matter what capital Y is.</span> </p><p><span
  m='169500'>Now, when we place ourselves in a conditional universe,
  where</span> <span m='172370'>capital Y takes a value, little y,</span> <span
  m='176280'>then the joint PMF of X and Y gets</span> <span
  m='179660'>concentrated on those values of capital Y</span> <span
  m='183500'>that obey this relation.</span> </p><p><span m='186080'>So
  conditioned on this event, capital Y</span> <span m='190190'>is, with
  certainty, equal to little y.</span> </p><p><span m='193490'>Therefore, this
  random variable here,</span> <span m='195970'>in the conditional universe, is
  the same as this number.</span> </p><p><span m='207210'>But now, since this is
  a number, it</span> <span m='209750'>can be pulled outside the
  expectation.</span> </p><p><span m='218740'>So we have concluded that for any
  outcome for which</span> <span m='223880'>the random variable, capital Y,
  takes this specific value,</span> <span m='227600'>little y, this random
  variable takes this value.</span> </p><p><span m='232260'>This random variable
  takes this value.</span> </p><p><span m='235110'>They are the same.</span>
  </p><p><span m='236970'>So no matter what the outcome is,</span> <span
  m='240050'>these two random variables take the same value,</span> <span
  m='242740'>and therefore they are the same random variables.</span>
  </p><p><span m='248130'>Now, this is a correct proof if the random
  variables</span> <span m='253290'>are discrete.</span> </p><p><span
  m='254625'>If the random variables are continuous or general,</span> <span
  m='258470'>then carrying out a rigorous proof is actually quite subtle,</span>
  <span m='263160'>and it is beyond our scope.</span> </p><p><span
  m='266430'>However, the intuition is still correct,</span> <span
  m='269960'>and the result is correct.</span> </p><p><span m='271990'>And we
  will be using it freely whenever we need to.</span> </p><p><span
  m='276780'>Let us now move to a second observation.</span> </p><p><span
  m='279980'>Suppose that h is an invertible function.</span> </p><p><span
  m='283260'>What does that mean?</span> </p><p><span m='284260'>That if I give
  you the value of h,</span> <span m='286770'>you can tell me the value of the
  argument.</span> </p><p><span m='289720'>So in some sense, Y and h of Y
  can</span> <span m='294980'>be recovered from each other.</span> </p><p><span
  m='296490'>If I give you Y, you can calculate h of Y.</span> </p><p><span
  m='299900'>But also, if I give you h of Y, you can figure out what Y
  was.</span> </p><p><span m='304870'>An example could be the function, h of
  Y,</span> <span m='309890'>equals Y to the third power.</span> </p><p><span
  m='314980'>If I tell you the value of Y, you know Y cubed.</span> </p><p><span
  m='318220'>But if I tell you Y cubed, you can also figure out Y.</span>
  </p><p><span m='321710'>So Y and Y cubed carry exactly the same
  information.</span> </p><p><span m='327180'>In that case, the conditional
  expectation--</span> <span m='330740'>what you expect, on the average, X to
  be-- if I tell you</span> <span m='333930'>the value of Y, should be the same
  as what you would expect</span> <span m='339159'>X to be if I give you the
  value of, let's say, Y cubed.</span> </p><p><span m='343670'>In both cases,
  I'm giving you the same amount of information,</span> <span m='347060'>so the
  conditional distribution of X should be the same.</span> </p><p><span
  m='350520'>And the conditional expectations should also be the same.</span>
  </p><p><span m='354060'>So this is, again, a very intuitive fact.</span>
  </p><p><span m='357730'>How do we verify that this fact is true?</span>
  </p><p><span m='360470'>Using the same method as before.</span> </p><p><span
  m='363610'>So fix some particular outcome for which</span> <span
  m='369950'>the random variable, capital Y, takes a specific value,
  little</span> <span m='374570'>y.</span> </p><p><span m='378610'>When that
  happens, this random variable</span> <span m='382080'>will take this value
  here.</span> </p><p><span m='385610'>That's just by the definition of
  conditional expectation.</span> </p><p><span m='388740'>This is the random
  variable that takes this value whenever</span> <span m='391720'>capital Y
  happens to be equal to little y.</span> </p><p><span m='396850'>In that case,
  we also have that h of capital</span> <span m='401650'>Y takes on a specific
  value, h of little y.</span> </p><p><span m='408659'>When this random variable
  takes this specific value,</span> <span m='414440'>this random variable here
  will take a value of this kind.</span> </p><p><span m='427830'>So this is the
  random variable that</span> <span m='431350'>takes this value whenever h of
  capital Y</span> <span m='435800'>happens to be this specific number.</span>
  </p><p><span m='439460'>But now, the event that h of Y takes this specific
  value,</span> <span m='445510'>because the function, h, is invertible,</span>
  <span m='448350'>is identical to the event that Y takes that particular
  value.</span> </p><p><span m='455750'>And so, since this event is identical to
  that event,</span> <span m='459620'>the conditional probabilities, given this
  event,</span> <span m='462207'>would be the same as the conditional
  probabilities given</span> <span m='464540'>that the event.</span>
  </p><p><span m='465560'>And therefore, the conditional expectations</span>
  <span m='468720'>would also be the same.</span> </p><p><span m='472800'>Once
  more, this is a proof that's</span> <span m='474780'>entirely rigorous if we
  are dealing</span> <span m='477110'>with discrete random variables,
  although</span> <span m='479630'>in the continuous case, there could</span>
  <span m='481640'>be some subtleties involved.</span> </p><p><span
  m='483870'>However, the result is true in general.</span> </p><p><span
  m='487040'>The technical details are beyond our scope.</span> </p><p></p>
uid: d12d2305e1c3f99b07308a6773ba4f80
type: courses
layout: video
---
