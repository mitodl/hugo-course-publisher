---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: mHonq7Gjjqg
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    title: Video-YouTube-Stream
    type: Video
    uid: d55a21a5bd0b4cabc93962b207663221
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/mHonq7Gjjqg/default.jpg'
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 1aba8dccbc40081468a50dcbfcf5a5e6
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: mHonq7Gjjqg
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 9001bd9afe5e085160b1654ab90da3bc
  - id: mHonq7Gjjqg.srt
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/derivation-of-the-law-of-total-variance/mHonq7Gjjqg.srt
    title: 3play caption file
    type: null
    uid: e19d893370e22e3e4cfd58b9dd3725b2
  - id: mHonq7Gjjqg.pdf
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/derivation-of-the-law-of-total-variance/mHonq7Gjjqg.pdf
    title: 3play pdf file
    type: null
    uid: c025b4baa48ff7801b96c3915ee62e5c
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 415203176cbdbcc86ba5fbbf54633f3c
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 9e60ce05d56402ad8244e471c68ad5e3
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L13-07_300k.mp4
    parent_uid: 396bdff28c4149afd5fe624dc57417b2
    title: Video-Internet Archive-MP4
    type: Video
    uid: 0367645fd3006af7f6d9f8b76440b1ee
inline_embed_id: 89485635derivationofthelawoftotalvariance46388736
order_index: 1266
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: derivation-of-the-law-of-total-variance
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/derivation-of-the-law-of-total-variance
title: Derivation of the Law of Total Variance
transcript: >-
  <p><span m='780'>We will now go through a derivation of the</span> <span
  m='2950'>law of total variance.</span> </p><p><span m='4790'>This particular
  derivation is not insightful.</span> </p><p><span m='8500'>It will not really
  give you any intuition as to why the</span> <span m='11380'>law of total
  variance is correct.</span> </p><p><span m='13580'>On the other hand, it
  involves some interesting manipulations</span> <span m='17270'>that will be
  useful to be able to follow, and understand the</span> <span m='21630'>kinds
  of objects that they're being moved around, and why</span> <span
  m='24870'>each step is valid.</span> </p><p><span m='26560'>Our derivation
  relies on the standard formula that we have</span> <span m='30400'>on how to
  calculate variances.</span> </p><p><span m='32610'>And our first step is to
  apply this formula to the</span> <span m='35630'>conditional variance.</span>
  </p><p><span m='37170'>Now, the conditional variance is like an ordinary
  variance,</span> <span m='40170'>except that it is calculated in a conditional
  universe.</span> </p><p><span m='43630'>So we apply this formula, except that
  the expectation of</span> <span m='48400'>X squared is the expectation
  calculated in</span> <span m='51520'>the conditional universe.</span>
  </p><p><span m='53240'>And similarly, for the next term it is the square of
  the</span> <span m='56880'>expected value of X. But it's the expected value of
  X as</span> <span m='60460'>calculated in the conditional universe.</span>
  </p><p><span m='66220'>So this is an equality between numbers.</span>
  </p><p><span m='75289'>What does it translate to?</span> </p><p><span
  m='79060'>This has been defined as a random variable that takes</span> <span
  m='82450'>this value when capital Y is equal to little y.</span> </p><p><span
  m='87400'>What is the random variable that takes this value when</span> <span
  m='91070'>capital Y is little y?</span> </p><p><span m='93500'>Well, this
  random variable here is a random variable that</span> <span m='99740'>takes
  this value when capital Y is equal to little y.</span> </p><p><span
  m='104390'>And this random variable here is a random variable that</span>
  <span m='111580'>takes this numerical value when capital Y is</span> <span
  m='114910'>equal to little y.</span> </p><p><span m='116350'>So to summarize,
  this is the random variable that takes</span> <span m='120290'>this numerical
  value when capital Y is</span> <span m='122430'>equal to little y.</span>
  </p><p><span m='124130'>And this is a random variable that takes this value
  when</span> <span m='127630'>capital Y is equal to little y.</span>
  </p><p><span m='130300'>This expression, the left hand side is equal to the
  right</span> <span m='133520'>hand side for all y's.</span> </p><p><span
  m='136010'>And therefore, this random variable and that random</span> <span
  m='139350'>variable always take the same numerical values no matter</span>
  <span m='143140'>what y happens to be.</span> </p><p><span m='145560'>So these
  are identical random variables.</span> </p><p><span m='148220'>And so we have
  this equality between random variables.</span> </p><p><span m='151940'>The
  next step as we're working towards calculating this first</span> <span
  m='156000'>term here in the law of total variance is to take the</span> <span
  m='159310'>expectation of this expression.</span> </p><p><span m='161720'>What
  is it?</span> </p><p><span m='163079'>We take the expectation of the first
  term.</span> </p><p><span m='165460'>It's the expectation of a conditional
  expectation.</span> </p><p><span m='168740'>And according to the law of
  iterated expectations, it is</span> <span m='172780'>the same as the
  unconditional expectation.</span> </p><p><span m='176460'>And then we have the
  expected value of the next term.</span> </p><p><span m='187888'>Next, we want
  to make some progress towards calculating</span> <span m='192110'>this second
  quantity in the law of total variance.</span> </p><p><span m='195280'>And the
  way to calculate it is to just apply this general</span> <span
  m='199329'>property of variances to the special case where X gets</span> <span
  m='203810'>replaced by the expected value of X given Y.</span> </p><p><span
  m='208160'>So the first term will be the expected value of our random</span>
  <span m='212520'>variable squared.</span> </p><p><span m='213910'>Our random
  variable is the expected value of X given Y.</span> </p><p><span
  m='220170'>And the second term involves the expected value of the</span> <span
  m='224490'>random variable whose variance we're considering.</span>
  </p><p><span m='227530'>So it's the expected value of this random
  variable.</span> </p><p><span m='232110'>So it's the expected value of the
  conditional expectation.</span> </p><p><span m='238690'>And everything gets
  squared.</span> </p><p><span m='242010'>What is this term?</span> </p><p><span
  m='243520'>By the law of iterated expectations, the expected</span> <span
  m='246570'>value of a conditional expectation is the same as the</span> <span
  m='251550'>unconditional expectation.</span> </p><p><span m='253990'>So this
  last term here is of this form.</span> </p><p><span m='259920'>What we will do
  next is to take this expression here and</span> <span m='265290'>that
  expression here, and add them together.</span> </p><p><span m='268990'>When we
  add them, we notice that this term and that term</span> <span m='272180'>are
  the same.</span> </p><p><span m='273260'>So they cancel out.</span>
  </p><p><span m='274850'>And we're left with the expected value of X
  squared</span> <span m='278490'>minus the square of the expected value.</span>
  </p><p><span m='282420'>But we know that this is the same as the variance of
  X. So</span> <span m='286159'>we have proved that the sum of these two terms,
  which are the</span> <span m='289600'>two terms up here, give us the variance
  of X.</span> </p>
uid: 396bdff28c4149afd5fe624dc57417b2
type: course
layout: video
---
