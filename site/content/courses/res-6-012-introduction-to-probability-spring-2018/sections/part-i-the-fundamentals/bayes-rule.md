---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: kz2tvO_ZAKI
    parent_uid: 1ce256796408575f96ebed3b52a87645
    title: Video-YouTube-Stream
    type: Video
    uid: 28dfa7c95f756126a200627e494bb4e0
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/kz2tvO_ZAKI/default.jpg'
    parent_uid: 1ce256796408575f96ebed3b52a87645
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 788cf965e48f5f0f657237ca4692e115
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: kz2tvO_ZAKI
    parent_uid: 1ce256796408575f96ebed3b52a87645
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 2717d91cb0d59885cd7aef454fd8bd10
  - id: kz2tvO_ZAKI.srt
    parent_uid: 1ce256796408575f96ebed3b52a87645
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/bayes-rule/kz2tvO_ZAKI.srt
    title: 3play caption file
    type: null
    uid: 0680f5b4c639e9aa9e16200c4cc61ac2
  - id: kz2tvO_ZAKI.pdf
    parent_uid: 1ce256796408575f96ebed3b52a87645
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/bayes-rule/kz2tvO_ZAKI.pdf
    title: 3play pdf file
    type: null
    uid: e037321b6080610c866ae62d10f2d8db
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 1ce256796408575f96ebed3b52a87645
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 3738f3dcc98e9e58b28ffb33b0d13c5d
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 1ce256796408575f96ebed3b52a87645
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 838f9efe01ffc9ac6109294008e8d2ac
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L02-08_300k.mp4
    parent_uid: 1ce256796408575f96ebed3b52a87645
    title: Video-Internet Archive-MP4
    type: Video
    uid: a16dc7275fd4173799bf4b44b4557b51
inline_embed_id: 22847884bayesrule91846676
order_index: 285
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: bayes-rule
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/bayes-rule
title: Bayes' Rule
transcript: >-
  <p><span m="2310">We now come to the third and final kind of calculation
  out</span> <span m="6930">of the calculations that we carried out</span> <span
  m="8780">in our earlier example.</span></p><p><span m="10640">The setting is
  exactly the same as in our discussion of</span> <span m="13110">the total
  probability theorem.</span></p><p><span m="15000">We have a sample space which
  is partitioned into a number</span> <span m="19040">of disjoint subsets or
  events which</span> <span m="22090">we think of as
  scenarios.</span></p><p><span m="24330">We're given the probability of each
  scenario.</span></p><p><span m="27440">And we think of these probabilities as
  being some</span> <span m="30790">kind of initial beliefs.</span></p><p><span
  m="32800">They capture how likely we believe each scenario to
  be.</span></p><p><span m="41140">Now, under each scenario, we also have the
  probability that</span> <span m="47050">an event of interest, event B, will
  occur.</span></p><p><span m="51520">Then the probabilistic experiment is
  carried out.</span></p><p><span m="54920">And perhaps we observe that event B
  did indeed occur.</span></p><p><span m="60100">Once that happens, maybe this
  should cause us to revise our</span> <span m="65239">beliefs about the
  likelihood of the different scenarios.</span></p><p><span m="69050">Having
  observed that B occurred, perhaps certain</span> <span m="73039">scenarios are
  more likely than others.</span></p><p><span m="76820">How do we revise our
  beliefs?</span></p><p><span m="78510">By calculating conditional
  probabilities.</span></p><p><span m="81220">And how do we calculate
  conditional probabilities?</span></p><p><span m="84340">We start from the
  definition of conditional probabilities.</span></p><p><span m="88130">The
  probability of one event given another is the</span> <span
  m="91520">probability that both events occur divided by the</span> <span
  m="95700">probability of the conditioning event.</span></p><p><span
  m="99180">How do we continue?</span></p><p><span m="101450">We simply realize
  that the numerator is what we can</span> <span m="105200">calculate using the
  multiplication rule.</span></p><p><span m="108229">And the denominator is
  exactly what we calculate using the</span> <span m="112590">total probability
  theorem.</span></p><p><span m="114720">So we have everything we need to
  calculate those revised</span> <span m="118860">beliefs, or conditional
  probabilities.</span></p><p><span m="121740">And this all there is in the
  Bayes rule.</span></p><p><span m="124340">It is actually a very simple
  calculation.</span></p><p><span m="129720">It's a very simple
  calculation.</span></p><p><span m="131710">However, it is a quite important
  one.</span></p><p><span m="134900">Its history goes way
  back.</span></p><p><span m="137650">In the middle of the 18th century, a
  Presbyterian</span> <span m="140960">minister, Thomas Bayes, worked it
  out.</span></p><p><span m="144310">It was published a few years after his
  death.</span></p><p><span m="147350">And it was quickly reorganized for its
  significance.</span></p><p><span m="150650">It's a systematic way for
  incorporating new evidence.</span></p><p><span m="154370">It's a systematic
  way for learning from experience.</span></p><p><span m="158220">And it forms
  the foundation of a major branch of mathematics,</span> <span
  m="162090">so-called Bayesian inference, which we will study in some</span>
  <span m="166090">detail later in this course.</span></p><p><span
  m="169880">The general idea is that we start with a probabilistic</span> <span
  m="173860">model, which involves a number of possible
  scenarios.</span></p><p><span m="177160">And we have some initial beliefs on
  the likelihood of</span> <span m="180820">each possible
  scenario.</span></p><p><span m="184430">There's also some particular event
  that may occur under</span> <span m="188590">each scenario.</span></p><p><span
  m="189600">And we know how likely it is to occur under each
  scenario.</span></p><p><span m="193450">This is our model of the
  situation.</span></p><p><span m="195800">Under each particular situation, the
  model tells us</span> <span m="199120">how likely event B is to
  occur.</span></p><p><span m="202272">If we actually observe that B occurred,
  then we use that</span> <span m="207350">information to draw conclusions about
  the possible</span> <span m="211180">causes of B, or conclusions about the
  more likely or less</span> <span m="216820">likely scenarios that may have
  caused this events to occur.</span></p><p><span m="221579">That's what
  inference is.</span></p><p><span m="224050">Having observed b, we make
  inferences as to how likely a</span> <span m="229450">particular scenario, Ai,
  is going to be.</span></p><p><span m="232670">And that likelihood is captured
  by this conditional</span> <span m="235490">probabilities of Ai, given the
  event B. So that's what the</span> <span m="240260">Bayes rule is
  doing.</span></p><p><span m="242000">Starting from conditional probabilities
  going in one</span> <span m="244430">direction, it allows us to calculate
  conditional</span> <span m="247020">probabilities going in the opposite
  direction.</span></p><p><span m="251320">It allows us to revise the
  probabilities of the different</span> <span m="255340">scenarios, taking into
  account the new information.</span></p><p><span m="258540">And that's exactly
  what inference is all about, as</span> <span m="262520">we're going to see
  later in this class.</span></p><p>&nbsp;</p>
uid: 1ce256796408575f96ebed3b52a87645
type: course
layout: video
---
