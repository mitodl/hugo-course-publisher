---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: zc6PfijY8_s
    parent_uid: 300632faa0f918e57d99368db0d6472e
    title: Video-YouTube-Stream
    type: Video
    uid: 3d2c7e12f8772f018cc30bd11acbdd88
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/zc6PfijY8_s/default.jpg'
    parent_uid: 300632faa0f918e57d99368db0d6472e
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: 5b48db10627fd544d83455b309954011
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: zc6PfijY8_s
    parent_uid: 300632faa0f918e57d99368db0d6472e
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 1583dc58bd9c703699f276972b8c5078
  - id: zc6PfijY8_s.srt
    parent_uid: 300632faa0f918e57d99368db0d6472e
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/lecture-overview-12/zc6PfijY8_s.srt
    title: 3play caption file
    type: null
    uid: c486ef2be9160549721639e19dfecac2
  - id: zc6PfijY8_s.pdf
    parent_uid: 300632faa0f918e57d99368db0d6472e
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/lecture-overview-12/zc6PfijY8_s.pdf
    title: 3play pdf file
    type: null
    uid: 15e4eab070e45eae746f4e28debb173f
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 300632faa0f918e57d99368db0d6472e
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 68cf15903c9f1c92399eaf2c6564c1ce
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 300632faa0f918e57d99368db0d6472e
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: d3ea6e2d4cb45e20829440143bf4d74b
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L13-01_300k.mp4
    parent_uid: 300632faa0f918e57d99368db0d6472e
    title: Video-Internet Archive-MP4
    type: Video
    uid: 225c3d7cf3bd9a43e188ca59105106f8
inline_embed_id: 98544836lectureoverview3397281
order_index: 1212
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: lecture-overview-12
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/lecture-overview-12
title: Lecture Overview
transcript: >-
  <p><span m='90'>By this point in this class, you must have realized that
  a</span> <span m='3000'>lot of revolves around the concept of
  conditioning.</span> </p><p><span m='6730'>Conditional expectations play a
  central role.</span> </p><p><span m='9900'>For this reason, it is useful to
  revisit this concept and</span> <span m='13100'>view it in a more abstract
  manner.</span> </p><p><span m='16040'>The basic idea is that the value of a
  conditional</span> <span m='18780'>expectation is affected by a random
  quantity by the value</span> <span m='23390'>of the random variable Y on which
  we are conditioning.</span> </p><p><span m='27400'>It is a function of Y and,
  therefore, a random variable.</span> </p><p><span m='32750'>Based on this
  observation, we will redefine the conditional</span> <span
  m='36130'>expectation as a random variable and then try to</span> <span
  m='39830'>understand its properties.</span> </p><p><span m='41950'>In
  particular, we will develop a formula for the expected</span> <span
  m='45430'>value of the conditional expectation.</span> </p><p><span
  m='48950'>This will be what as known as the law of iterated</span> <span
  m='52900'>expectations.</span> </p><p><span m='55330'>After doing all this, we
  will follow a similar program for</span> <span m='58640'>the conditional
  variance.</span> </p><p><span m='60800'>Once more, we will see that it can
  be</span> <span m='62930'>viewed as a random variable.</span> </p><p><span
  m='65060'>And then we will relate its expected value with the</span> <span
  m='68400'>unconditional variance.</span> </p><p><span m='70590'>This will be
  the so-called law of total variance.</span> </p><p><span m='75940'>As an
  illustration of the tools we are introducing in</span> <span m='78800'>this
  lecture, we will consider various examples that will</span> <span
  m='82330'>hopefully clarify the concepts involved.</span> </p><p><span
  m='85880'>Our final and most important example will involve the sum</span>
  <span m='89789'>of a random number of independent random variables.</span>
  </p><p><span m='94490'>The setting here is more challenging than the
  case</span> <span m='97050'>where we add a fixed number of random
  variables.</span> </p><p><span m='100450'>But by using conditioning, we will
  be able to derive</span> <span m='104050'>formulas for the mean and the
  variance.</span> </p><p></p>
uid: 300632faa0f918e57d99368db0d6472e
type: courses
layout: video
---
