---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: aGbP_7yAiEk
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    title: Video-YouTube-Stream
    type: Video
    uid: 46699483b950e8a19a1556b918c00170
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/aGbP_7yAiEk/default.jpg'
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: e91741e341471c164086c34981248c7c
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: aGbP_7yAiEk
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: 23237135eb386c25a36bec1733c7f401
  - id: aGbP_7yAiEk.srt
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/the-sum-of-independent-normal-random-variables/aGbP_7yAiEk.srt
    title: 3play caption file
    type: null
    uid: 7a98c259797f4ad5a5afc6d9fd3c2652
  - id: aGbP_7yAiEk.pdf
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/the-sum-of-independent-normal-random-variables/aGbP_7yAiEk.pdf
    title: 3play pdf file
    type: null
    uid: 4ac874aed59d36adc17404c89bf57288
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: 175a74e8d478e6790f126ec11754fe38
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: b7be0f3260261c71ef37138c093e4445
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L12-04_300k.mp4
    parent_uid: 9f033515a1dcb0a57813d678180708fb
    title: Video-Internet Archive-MP4
    type: Video
    uid: 2f882640bf4e6eedf6e68643f3cf4913
inline_embed_id: 83844467thesumofindependentnormalrandomvariables31048567
order_index: 1122
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: the-sum-of-independent-normal-random-variables
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/the-sum-of-independent-normal-random-variables
title: The Sum of Independent Normal Random Variables
transcript: >-
  <p><span m='1670'>In this brief segment, we will discuss</span> <span
  m='3465'>an important application of the convolution formula.</span>
  </p><p><span m='7970'>Suppose that X is a normal random variable with a
  given</span> <span m='11360'>mean and variance.</span> </p><p><span
  m='12300'>So that the PDF of X takes this form.</span> </p><p><span
  m='14950'>And similarly, Y is normal with a given mean and variance.</span>
  </p><p><span m='18140'>So its PDF takes this form.</span> </p><p><span
  m='20020'>We assume that X and Y are independent.</span> </p><p><span
  m='22800'>And we're interested in the sum of the two random variables</span>
  <span m='26740'>X and Y. And we wish to derive the PDF of Z.</span>
  </p><p><span m='30410'>Of course, the PDF of Z is given by the convolution
  formula.</span> </p><p><span m='35040'>And now we plug in here, the form for
  the density of X.</span> </p><p><span m='40040'>And here, we plug the form of
  the density of Y.</span> </p><p><span m='43250'>Except that instead of the
  argument Y,</span> <span m='45950'>we need to put in the argument z minus
  x.</span> </p><p><span m='49240'>So we obtain this form, where here we</span>
  <span m='51320'>have a z minus x instead of y.</span> </p><p><span
  m='54690'>Now this is an integral that looks pretty complicated.</span>
  </p><p><span m='58460'>But it is not too hard to do.</span> </p><p><span
  m='61260'>One just needs to be patient, rearrange terms, collect terms.</span>
  </p><p><span m='65470'>And the details of the calculations</span> <span
  m='67620'>are not as interesting.</span> </p><p><span m='69720'>So we will
  skip them for now.</span> </p><p><span m='72240'>And I will just tell you that
  the final answer</span> <span m='74590'>takes this form.</span> </p><p><span
  m='76310'>What is this form?</span> </p><p><span m='77450'>Well, it's
  exponential of minus z</span> <span m='80130'>minus something squared divided
  by a constant.</span> </p><p><span m='83870'>And we recognize that this is the
  form</span> <span m='85610'>of a normal random variable.</span> </p><p><span
  m='88240'>It's a normal random variable whose mean</span> <span m='91510'>is
  given by this term here, it's mu x plus mu y.</span> </p><p><span
  m='97970'>And the variance of that normal random variable</span> <span
  m='100750'>is that constant that appears next to the factor of 2</span> <span
  m='103520'>in the denominator.</span> </p><p><span m='105130'>So the sum of
  these two normal random variables,</span> <span m='108320'>these two
  independent normal random variables,</span> <span m='110850'>is also
  normal.</span> </p><p><span m='112166'>The fact that this is the mean and
  this</span> <span m='113789'>is the variance of the sum, of course, is not a
  surprise.</span> </p><p><span m='117190'>What is important in this result that
  we have here</span> <span m='120490'>is that the sum is actually
  normal.</span> </p><p><span m='123800'>Now, we carried out this
  argument</span> <span m='125600'>for the case of the sum of two normal random
  variables.</span> </p><p><span m='129590'>But suppose that we had the sum of
  three</span> <span m='133630'>independent normal random variables,</span>
  <span m='135860'>what can we say about it?</span> </p><p><span m='137870'>By
  the result that we just discussed, this sum is normal.</span> </p><p><span
  m='142640'>This is assumed to be normal.</span> </p><p><span m='144340'>We
  assume that X, Y, and W are independent.</span> </p><p><span
  m='147490'>Therefore, this sum is independent from W.</span> </p><p><span
  m='151560'>So we're dealing with the sum of two</span> <span
  m='153980'>independent normal random variables again.</span> </p><p><span
  m='157140'>So this sum here is going to be normal as well.</span> </p><p><span
  m='160430'>And we continue this argument by induction,</span> <span
  m='163070'>and conclude that more generally,</span> <span m='165110'>the sum
  of any finite number of independent normal random</span> <span
  m='168329'>variables is normal.</span> </p><p><span m='170160'>This is a very
  important, but also useful fact.</span> </p><p><span m='172850'>It means that
  when we start working</span> <span m='174780'>with normal random variables,
  very often</span> <span m='177050'>we stay within the realm of normal random
  variables.</span> </p><p><span m='180150'>We can form linear functions of
  them,</span> <span m='182890'>take linear combinations of them,</span> <span
  m='184830'>and still remain in the world of normal random variables.</span>
  </p>
uid: 9f033515a1dcb0a57813d678180708fb
type: courses
layout: video
---
