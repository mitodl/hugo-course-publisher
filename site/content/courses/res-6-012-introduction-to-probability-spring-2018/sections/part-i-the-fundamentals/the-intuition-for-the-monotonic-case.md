---
about_this_resource_text: '<p><strong>Instructor:</strong> John Tsitsiklis</p>'
embedded_media:
  - id: Video-YouTube-Stream
    media_location: zM39sZL9oGE
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    title: Video-YouTube-Stream
    type: Video
    uid: 5ef6f6d5b790aba7aef79b782cb4fee5
  - id: Thumbnail-YouTube-JPG
    media_location: 'https://img.youtube.com/vi/zM39sZL9oGE/default.jpg'
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    title: Thumbnail-YouTube-JPG
    type: Thumbnail
    uid: ea01266a282dc31bc0cdc8f83f6c019f
  - id: 3Play-3PlayYouTubeid-MP4
    media_location: zM39sZL9oGE
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    title: 3Play-3Play YouTube id
    type: 3Play
    uid: b4f8c2ab41135bbb1b8b62e659fa9c79
  - id: zM39sZL9oGE.srt
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/the-intuition-for-the-monotonic-case/zM39sZL9oGE.srt
    title: 3play caption file
    type: null
    uid: e3c428e9908fecb50cf44f39e6aa8ec6
  - id: zM39sZL9oGE.pdf
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    technical_location: >-
      https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/the-intuition-for-the-monotonic-case/zM39sZL9oGE.pdf
    title: 3play pdf file
    type: null
    uid: be25bb7d88451cea15c781affede3d87
  - id: Caption-3Play YouTube id-SRT
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    title: Caption-3Play YouTube id-SRT-English - US
    type: Caption
    uid: d636f72fd8ec5286995f24ccc863bcb6
  - id: Transcript-3Play YouTube id-PDF
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    title: Transcript-3Play YouTube id-PDF-English - US
    type: Transcript
    uid: 68dcf0a533d374f09ce995e59e02df99
  - id: Video-InternetArchive-MP4
    media_location: >-
      https://archive.org/download/MITRES.6-012S18/MITRES6_012S18_L11-07_300k.mp4
    parent_uid: 5d486b203c49e7e232916f6827fc02bf
    title: Video-Internet Archive-MP4
    type: Video
    uid: 9d5e242a514329a087ca59a02138d780
inline_embed_id: 6187119theintuitionforthemonotoniccase54315522
order_index: 1068
parent_uid: 9ca6b310dc93095c9ac0f0e5f95e6930
related_resources_text: ''
short_url: the-intuition-for-the-monotonic-case
technical_location: >-
  https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/the-intuition-for-the-monotonic-case
title: The Intuition for the Monotonic Case
transcript: >-
  <p><span m='1150'>The formula that we just derived for the monotonic
  case</span> <span m='4700'>has a nice intuitive explanation that we
  will</span> <span m='7290'>develop now.</span> </p><p><span m='8770'>Suppose
  that g is a monotonic function of x and that it's</span> <span
  m='13320'>monotonically increasing.</span> </p><p><span m='15780'>Let us fix a
  particular x and a corresponding y so that the</span> <span m='23100'>two of
  them are related as follows-- y is equal to g of</span> <span m='28420'>x, or
  we could argue in terms of the inverse function so</span> <span m='33750'>that
  x is equal to h of y.</span> </p><p><span m='38200'>Recall that h is the
  inverse function, that given a value</span> <span m='41610'>of y, tells us
  which one is the corresponding value of x.</span> </p><p><span m='45880'>Now
  let us consider a small interval in the</span> <span m='50000'>vicinity of
  this x.</span> </p><p><span m='52950'>Whenever x falls somewhere in this
  range, then y is going to</span> <span m='57960'>fall inside another small
  interval.</span> </p><p><span m='61530'>The event that x belongs here is the
  same as the event that</span> <span m='65480'>y belongs there.</span>
  </p><p><span m='67310'>So these two events have the same probability.</span>
  </p><p><span m='71590'>And we can, therefore, write that the probability that
  Y</span> <span m='79110'>falls in this interval is the same as the probability
  that X</span> <span m='90390'>falls in the corresponding little interval on
  the x-axis.</span> </p><p><span m='97350'>This interval has a certain length
  delta 1.</span> </p><p><span m='99610'>This interval has a certain length
  delta 2.</span> </p><p><span m='102759'>Now remember our interpretation
  of</span> <span m='106880'>probabilities of small intervals in terms of PDFs
  so</span> <span m='111229'>this probability here is approximately equal to the
  PDF</span> <span m='115620'>of Y evaluated at the point y times the length of
  the</span> <span m='121100'>corresponding interval.</span> </p><p><span
  m='123560'>Similarly, on the other side, the probability that X falls</span>
  <span m='128259'>on the interval is the PDF of X times the</span> <span
  m='133050'>length of that interval.</span> </p><p><span m='135260'>So this
  gives us already a relation between the PDF of Y</span> <span m='138670'>and
  the PDF of X, but it involves those two numbers</span> <span m='142350'>delta
  1 and delta 2.</span> </p><p><span m='144590'>How are these two numbers
  related?</span> </p><p><span m='150400'>If x moves up by the amount of delta
  1, how much is y going</span> <span m='156670'>to move up?</span> </p><p><span
  m='158780'>It's going to move up by an amount which is delta 1 times</span>
  <span m='163640'>the slope of the function g at that particular point.</span>
  </p><p><span m='169030'>So that gives us one relation that delta 2 is
  approximately</span> <span m='175500'>equal to delta 1 times the derivative of
  the function of</span> <span m='179890'>g at that particular x.</span>
  </p><p><span m='186710'>However, it's more useful to work the other way,
  thinking</span> <span m='190930'>in terms of the inverse function.</span>
  </p><p><span m='196260'>The inverse function maps y to x, and it maps y plus
  delta to</span> <span m='202200'>2 to x plus delta 1.</span> </p><p><span
  m='205960'>When y advances by delta 2, x is going to advance by an</span>
  <span m='211390'>amount which is how much y advanced times the slope,
  or</span> <span m='218990'>the derivative, of the function that</span> <span
  m='221060'>maps y's into x's.</span> </p><p><span m='223670'>And this function
  is the inverse function.</span> </p><p><span m='231600'>So this is the
  relation that we're going to use.</span> </p><p><span m='235940'>And so we
  replace delta 1 by this expression that we have</span> <span m='243480'>here
  in terms of delta 2.</span> </p><p><span m='251940'>And now we cancel the
  delta 2 from both sides of this</span> <span m='256390'>equality, and we
  obtain the final formula that the PDF of</span> <span m='262140'>Y evaluated
  at a certain point is equal to the PDF of x</span> <span m='274270'>evaluated
  at the corresponding point, or we could write this</span> <span m='280240'>as
  the PDF of X evaluated at the value x that's associated</span> <span
  m='286010'>to that y that's given by the inverse function, times the</span>
  <span m='290930'>derivative of the function h, the inverse function.</span>
  </p><p><span m='300420'>And this is just the same formula as the one that we
  had</span> <span m='303870'>derived earlier using CDFs.</span> </p><p><span
  m='308100'>This derivation is quite intuitive.</span> </p><p><span
  m='311470'>It associates probabilities of small intervals on the x-axis</span>
  <span m='315760'>to probabilities of corresponding small intervals</span>
  <span m='318550'>on the y-axis.</span> </p><p><span m='319820'>These two
  probabilities have to be equal, and this implies</span> <span m='323150'>a
  certain relation between the two PDFs.</span> </p><p></p>
uid: 5d486b203c49e7e232916f6827fc02bf
type: course
layout: video
---
